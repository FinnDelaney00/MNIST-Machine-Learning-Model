
This project is a basic neural network built from scratch using Python and NumPy to classify handwritten digits from the MNIST dataset. It uses a simple two-layer neural network trained with gradient descent.

How It Works
Input: Images from the MNIST dataset (28x28 pixels, flattened to 784 values).
Output: A predicted label for each image (0 to 9).

Model:
One hidden layer with 10 neurons using ReLU activation.
An output layer with 10 neurons using Softmax to classify digits.

Requirements
Python 3.x
NumPy
Pandas (for loading data)
Matplotlib (for visualizing images, optional)

What You Will Learn
How to implement a simple neural network without using external libraries like TensorFlow or PyTorch.
Basics of forward and backward propagation.
How to train a model using gradient descent.

Acknowledgments
Kaggle's MNIST Dataset
